{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据：从文本中构建词向量\n",
    "\n",
    "### 分词：切分文本成词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'book',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'book',\n",
       " 'on',\n",
       " 'Python',\n",
       " 'or',\n",
       " 'M.L.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'laid',\n",
       " 'eyes',\n",
       " 'upon.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mySent = \"This book is the best book on Python or M.L. I have ever laid eyes upon.\"\n",
    "mySent.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'book', 'is', 'the', 'best', 'book', 'on', 'Python', 'or', 'M']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# 切分除单词、数字外的任意字符串\n",
    "regEx = re.compile('\\\\W+')\n",
    "listOfTokens = regEx.split(mySent)\n",
    "listOfTokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'book', 'is', 'the', 'best', 'book', 'on']\n",
      "['this', 'book', 'is', 'the', 'best', 'book', 'on']\n"
     ]
    }
   ],
   "source": [
    "print([tok for tok in listOfTokens if len(tok) > 0][:7])\n",
    "print([tok.lower() for tok in listOfTokens if len(tok) > 0][:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello,\\n\\nSi'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emailText = open('email/ham/6.txt').read()\n",
    "\n",
    "# Above way of calling failed because of the Windows-1252 encode\n",
    "# Here is a better one\n",
    "with open('email/ham/6.txt', encoding='cp1252')\\\n",
    "        as datafile:\n",
    "    emailText = datafile.read()\n",
    "emailText[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfTokens = regEx.split(emailText)\n",
    "len(listOfTokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成词汇表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['steak', 'love', 'my', 'quit', 'dog', 'cute', 'ate', 'I', 'food', 'problems']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用函数createVocabList完成切分\n",
    "import bayes\n",
    "listOPost, listClasses = bayes.loadDataSet()\n",
    "myVocabList = bayes.createVocabList(listOPost)\n",
    "myVocabList[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 1, 0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bayes.bagOfWords2Vec(myVocabList, listOPost[0])[:10])\n",
    "print(bayes.bagOfWords2Vec(myVocabList, listOPost[3])[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练算法-从词向量计算概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.56494936 -2.56494936 -1.87180218 -3.25809654 -2.56494936]\n",
      "[-3.04452244 -3.04452244 -3.04452244 -2.35137526 -1.94591015]\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "listOPost, listClassesOPost = bayes.loadDataSet()\n",
    "trainMat = []\n",
    "for postinDoc in listOPost:\n",
    "    trainMat.append(bayes.bagOfWords2Vec(myVocabList,\n",
    "                                        postinDoc))\n",
    "p0V, p1V, pAb = bayes.train(trainMat, listClasses)\n",
    "print(p0V[:5])\n",
    "print(p1V[:5])\n",
    "print(pAb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试过程-根据现实情况修改分类器\n",
    "\n",
    "为了与习题（3）作比较，这里修改了源码，使用相同的训练集与测试集进行训练与测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification error  1 ['just', '750', 'just', 'just', 'just', 'just', 'just', 'just', 'just', 'just', 'just', 'just', 'just', 'just', 'just', 'just', 'just', 'just', 'just', 'just', 'just', 'just', 'just', 'just', 'just', 'just', 'just', 'service', 'service', 'just']\n",
      "The error rate is  0.1\n"
     ]
    }
   ],
   "source": [
    "# bayes.spamTest()\n",
    "import bayesEdit\n",
    "train_X, train_Y, test_X, test_Y = bayesEdit.spamTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 操作练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验中如何解决零概率问题\n",
    "\n",
    "这里采用拉普拉斯平滑，相关代码为bayes.py的44行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayes.py line 44\n",
    "    p0Num=ones(numWords);p1Num=ones(numWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何解决概率值太小会产生溢出问题\n",
    "\n",
    "这里没有直接算出概率值，而是使用对数似然$\\log P(x|c)$来进行等价与$P(x|c)$的计算，将连乘转化为连加后，不会发生太小溢出，相关代码为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayes.py line 53,54\n",
    "    p1Vec=log(p1Num/p1Denom)\n",
    "    p0Vec=log(p0Num/p0Denom)\n",
    "# bayes.py line 59,60\n",
    "    p1=sum(vec2classfy*p1Vec)+log(pClass1)\n",
    "    p0=sum(vec2classfy*p0Vec)+log(1-pClass1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用sklearn中不同的NB分类器分类该数据集\n",
    "\n",
    "查看sklearn文档，我们发现关于Naive Bayes的分类器有四种：\n",
    "* Gaussian Naive Bayes\n",
    "* Multinomial Naive Bayes\n",
    "* Complement Naive Bayes(Not supported in sklearn 0.0)\n",
    "* Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "mnb.fit(train_X, train_Y)\n",
    "round(1.0 - mnb.score(test_X, test_Y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "bnb.fit(train_X, train_Y)\n",
    "1.0 - bnb.score(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，对于生成的某一组训练集&数据集，使用Gaussian，Multinomial或者直接的均匀先验的朴素贝叶斯的测试集准确率达到90%，而使用Bernoulli先验的朴素贝叶斯分类器测试集的准确率只有0.4。尽管由于数据量太小，结果的偏差十分巨大，但是我们还是能看到，bernoulli这种把属性直接归为出现/不出现十分粗糙，它忽略了词频信息，计算上不是正确的，分类结果十分差，而其他模型表现还算可以。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 疑惑\n",
    "\n",
    "在bayes.py中，函数*train()*中计算每个类所有单词出现总的次数p0Num初始化为2.0，这里我猜测是因为对于词$word_i$，它在一封email中可能出现的次数为任意自然数，所以使用laplacian correction时，不能取无穷，但是通常来说，最多的情况是，$word_i$出现的时候，次数大多都是1，所以分母中的校子取为2。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
